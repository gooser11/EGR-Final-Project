import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

########
# TODO REPLACE THIS SECTION WITH CODE TO LOAD YOUR DATASET INTO A PANDAS DATAFRAME
# Load Twitch dataset
df = pd.read_csv("twitchdata-update.csv")

# Select features and label
features = ['Watch time(Minutes)', 'Average viewers', 'Partnered']
df['Partnered'] = df['Partnered'].astype(int)
data = df[features].dropna()
labels = df.loc[data.index, 'Followers gained']

X = data.reset_index(drop=True)
y = labels.to_numpy()

# Remove NaNs in target
mask = ~np.isnan(y)
X = X[mask]
y = y[mask]

kf = KFold(n_splits=5)

beta, RMSE_train, RMSE_test, R2_train, R2_test = [], [], [], [], []

for train_idx, test_idx in kf.split(X):
    xTrain, xTest = X.loc[train_idx], X.loc[test_idx]
    yTrain, yTest = y[train_idx], y[test_idx]

    # Fill missing with median and standardize
    med_val = xTrain.median()
    xTrain = pd.DataFrame(StandardScaler().fit_transform(xTrain.fillna(med_val)), columns=X.columns)
    xTest = pd.DataFrame(StandardScaler().fit_transform(xTest.fillna(med_val)), columns=X.columns)

    model = LinearRegression()
    model.fit(xTrain, yTrain)

    y_pred_train = model.predict(xTrain)
    y_pred_test = model.predict(xTest)

    beta.append(model.coef_)
    RMSE_train.append(mean_squared_error(yTrain, y_pred_train, squared=False))
    RMSE_test.append(mean_squared_error(yTest, y_pred_test, squared=False))
    R2_train.append(r2_score(yTrain, y_pred_train))
    R2_test.append(r2_score(yTest, y_pred_test))

# Feature importance
avg_beta = np.mean(beta, axis=0)
importance_df = pd.DataFrame({
    "Feature": X.columns,
    "Average Coefficient": avg_beta,
    "Absolute Importance": np.abs(avg_beta)
}).sort_values(by="Absolute Importance", ascending=False)

print(importance_df[['Feature', 'Average Coefficient']])

# Scatterplot of most important feature
top_feature = importance_df.iloc[0]['Feature']

# Simple regression on top feature only
X_top = X[[top_feature]]
kf = KFold(n_splits=5)
plt.figure(figsize=(8, 6))

for i, (train_idx, test_idx) in enumerate(kf.split(X_top)):
    xTrain, xTest = X_top.iloc[train_idx], X_top.iloc[test_idx]
    yTrain, yTest = y[train_idx], y[test_idx]

    model = LinearRegression()
    model.fit(xTrain, yTrain)

    x_line = np.linspace(X_top[top_feature].min(), X_top[top_feature].max(), 100).reshape(-1, 1)
    y_line = model.predict(x_line)

    plt.scatter(xTrain, yTrain, color='blue', alpha=0.5, label='Train' if i == 0 else "")
    plt.scatter(xTest, yTest, color='orange', alpha=0.5, label='Test' if i == 0 else "")
    plt.plot(x_line, y_line, color='black', linestyle='--' if i == 0 else '-', alpha=0.4)

plt.xlabel(top_feature)
plt.ylabel('Followers Gained')
plt.title(f'Followers Gained vs {top_feature}')
plt.legend()
plt.savefig('watchtime_vs_followers.png')
plt.show()
